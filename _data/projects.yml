
- layout: top-middle
  #name: Deterministic Routing between Layout Abstractions for Multi-Scale Classification of Visually Rich Documents <br/><br/>
  #link: <a href="www.researchgate.net/publication/333859687_Visual_Segmentation_for_Information_Extraction_from_Heterogeneous_Visually_Rich_Documents" target="_blank">The Ohio State University</a>
  #github: Github page for project (eg. sproogen/modern-resume-theme)(optional)
  #quote: 
   #<img src="assets/laddernet_workflow.jpg" alt="Laddernet Workflow" width="500" height="170" style="align:center">
  description: <strong>C4. Improving Information Extraction from Visually Rich Documents using Visual Span Representations</strong><br/> <strong>TLDR:</strong> A visually rich document refers to a document where visual features play an important role in its semantics. We investigate whether incorporating domain-specific knowledge to encode the context of a visual span helps the downsteam performance of an IE task. Our results show context representation learned using a multimodal bi-LSTM network improves end-to-end performance on four separate IE tasks. <br/><br/> <strong>Conference:</strong> 47th International Conference on Very Large Data Bases (VLDB), 2021 <br/> <strong>Authors:</strong> Ritesh Sarkhel, Arnab Nandi <br/> <strong>Full-text</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/papers/V2_EWR_VLDB.pdf" download><u>here</u></a>, <strong>Slides</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/slides/ewr_vldb.pdf" download><u>here</u></a> <br/><br/>


- layout: top-middle
  #name: Deterministic Routing between Layout Abstractions for Multi-Scale Classification of Visually Rich Documents <br/><br/>
  #link: <a href="www.researchgate.net/publication/333859687_Visual_Segmentation_for_Information_Extraction_from_Heterogeneous_Visually_Rich_Documents" target="_blank">The Ohio State University</a>
  #github: Github page for project (eg. sproogen/modern-resume-theme)(optional)
  #quote: 
   #<img src="assets/laddernet_workflow.jpg" alt="Laddernet Workflow" width="500" height="170" style="align:center">
  description: <strong>C3. Interpretable Multi-Headed Attention for Abstractive Summarization at Controllable Lengths</strong><br/> <strong>TLDR:</strong> We propose a supervised method for generating abstractive summaries within a user-specified length. We develop a length-aware encoder-decoder network that constructs a representative summary by leveraging an interpretable attention mechanism. We obtain strong results on two low-resource domains.<br/><br/> <strong>Conference:</strong> 28th International Conference on Computational Linguistics (COLING), 2020 <br/> <strong>Authors:</strong> Ritesh Sarkhel, Moniba Keymanesh, Arnab Nandi, Srinivasan Parthasarathy <br/> <strong>Full-text</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/papers/MLS.pdf" download><u>here</u></a><br/><br/>


- layout: top-middle
  #name: Deterministic Routing between Layout Abstractions for Multi-Scale Classification of Visually Rich Documents <br/><br/>
  #link: <a href="www.researchgate.net/publication/333859687_Visual_Segmentation_for_Information_Extraction_from_Heterogeneous_Visually_Rich_Documents" target="_blank">The Ohio State University</a>
  #github: Github page for project (eg. sproogen/modern-resume-theme)(optional)
  #quote: 
   #<img src="assets/laddernet_workflow.jpg" alt="Laddernet Workflow" width="500" height="170" style="align:center">
  description: <strong>C2. Deterministic Routing between Layout Abstractions for Multi-Scale Classification of Visually Rich Documents</strong><br/> <strong>TLDR:</strong> We propose a fast, multi-scale classifier for visually rich documents. For fast inference, we define an attention-like operator that extracts visual features from a hierarchical abstraction defined for each document. We obtain state-of-the-art results on multiple benchmark datasets.<br/><br/> <strong>Conference:</strong> 28th International Joint Conference on Artificial Intelligence (IJCAI), 2019 <br/> <strong>Authors:</strong> Ritesh Sarkhel, Arnab Nandi <br/> <strong>Full-text</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/papers/ladderNet.pdf" download><u>here</u></a>, <strong>Slides</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/slides/ladderNet_PPT.pdf" download><u>here</u></a> <br/><br/>
  
- layout: top-middle
  #name: Visual Segmentation for Information Extraction from Heterogeneous Visually Rich Documents <br/><br/>
  #link: <a href="www.researchgate.net/publication/333859687_Visual_Segmentation_for_Information_Extraction_from_Heterogeneous_Visually_Rich_Documents" target="_blank">The Ohio State University</a>
  #github: Github page for project (eg. sproogen/modern-resume-theme)(optional)
  #quote: 
   #<img src="assets/segment_select_workflow.jpg" alt="Segment-Select Workflow" width="500" height="190" style="align:center">
  description: <strong>C1. Visual Segmentation for Information Extraction from Heterogeneous Visually Rich Documents</strong><br/> <strong>TLDR:</strong> We hypothesize that every visually rich document is comprised of a set of isolated, semantically coherent areas called logical blocks. We propose a divide-and-conquer approach for information extraction leveraging this bag-of-logical-blocks representation. Our end-to-end workflow does not utilize any type or format specific features, making it robust towards heterogeneous documents.<br/><br/> <strong>Conference:</strong> International Conference on Management of Data (SIGMOD), 2019 <br/> <strong>Authors:</strong> Ritesh Sarkhel, Arnab Nandi <br/> <strong>Full-text</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/papers/segment_Select.pdf" download><u>here</u></a>, <strong>Slides</strong> -- <a href="https://github.com/sarkhelritesh/sarkhelritesh.github.io/blob/master/slides/segment_Select_PPT.pdf" download><u>here</u></a> <br/><br/>
  
  
  
 
  
  
 
